{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup:\n",
    "# https://towardsdatascience.com/step-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468 \n",
    "# and https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook?authuser=1#console \n",
    "\n",
    "# Import all libraries needed for fitting ALS collbaorative filtering model on SQL dataframe\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "# for working with sql dataframes\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a SparkSession\n",
    "sparkSess = SparkSession.builder.appName('movieApp').getOrCreate()\n",
    "# read the data with schema\n",
    "# data = sparkSess.read.csv('./ml-latest-small/ratings.csv',inferSchema=True,header=True)\n",
    "data = sparkSess.read.csv('gs://bucket-capstoneudacitydatascience/ml-latest/ratings.csv',inferSchema=True,header=True)\n",
    "sparkSess.sparkContext.defaultParallelism, data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 75.073 seconds\n",
      "For rank 4, the validation RMSE is 0.85267451103\n",
      "Training completed in 70.074 seconds\n",
      "For rank 8, the validation RMSE is 0.860100462408\n",
      "Training completed in 76.208 seconds\n",
      "For rank 12, the validation RMSE is 0.859417291424\n",
      "The best model was trained with rank 4\n",
      "Training completed in 59.286 seconds\n",
      "The model had a RMSE on the test set of 0.852109611708\n"
     ]
    }
   ],
   "source": [
    "########### Training and validation of model #############\n",
    "##########################################################\n",
    "\n",
    "# a range for the number of latent factors in ALS model \n",
    "ranks = [4, 8, 12]\n",
    "# value of regularization\n",
    "reg_Param = 0.01\n",
    "# maximum nuber of iterations for training \n",
    "max_Iter = 5\n",
    "\n",
    "# split data in trainig testing and validation subsets\n",
    "(training, validation, test) = data.randomSplit([0.6, 0.2, 0.2])\n",
    "# intialize fixed part of ALS model\n",
    "als = ALS(maxIter=max_Iter, regParam=reg_Param, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "# define RMSE evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "    # Set the rank here\n",
    "    als.setRank(rank)\n",
    "    # record training time \n",
    "    t0 = time()\n",
    "    # fit the model with these parameters\n",
    "    model = als.fit(training)\n",
    "    tt = time() - t0\n",
    "    print (\"Training completed in {} seconds\".format(round(tt,3)))    \n",
    "    \n",
    "    # create rating predictions against the validation dataframe\n",
    "    predict_df_val = model.transform(validation)\n",
    "    # remove NaN values from predictions \n",
    "    predicted_ratings_df_val = predict_df_val.filter(predict_df_val.prediction != float('nan'))\n",
    "    # evaluate rmse for predicted ratings\n",
    "    error = evaluator.evaluate(predicted_ratings_df_val)\n",
    "\n",
    "    print ('For rank %s, the validation RMSE is %s' % (rank, error))\n",
    "    # record the best rank\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank %s' % best_rank)\n",
    "# fit the model for best rank\n",
    "als.setRank(best_rank)\n",
    "t0 = time()\n",
    "model = als.fit(training)\n",
    "tt = time() - t0\n",
    "print (\"Training completed in {} seconds\".format(round(tt,3)))    \n",
    "\n",
    "# compute rmse for testing dataset \n",
    "predict_df = model.transform(test)\n",
    "predicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n",
    "test_RMSE = evaluator.evaluate(predicted_test_df)\n",
    "print('The model had a RMSE on the test set of {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed in 0.038 seconds\n",
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|   2502|    11|  4.146366|\n",
      "|   2791|    11| 3.9784715|\n",
      "|   1282|    11| 3.6588442|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try creating recommendation for a user \n",
    "single_user = test.filter(test['userId']==11).select(['movieId','userId'])\n",
    "t0 = time()\n",
    "reccomendations = model.transform(single_user)\n",
    "tt = time() - t0\n",
    "print (\"Prediction completed in {} seconds\".format(round(tt,3)))    \n",
    "reccomendations.orderBy('prediction',ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SparkContext to create resilient distributed dataset (RDD) \n",
    "# ratings_raw_data = sparkSess.sparkContext.textFile('./ml-latest-small/ratings.csv')\n",
    "ratings_raw_data = sparkSess.sparkContext.textFile('gs://bucket-capstoneudacitydatascience/ml-latest/ratings.csv',10)\n",
    "# re-format rdd for usage with ALS \n",
    "ratings_raw_data_header = ratings_raw_data.take(1)[0]\n",
    "# remove header and separate (userID, movieID, rating)\n",
    "ratings_rdd = ratings_raw_data.filter(lambda line: line!=ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n",
    "sparkSess.sparkContext.defaultParallelism, data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 166.108 seconds\n",
      "For rank 4, the validation RMSE is 0.85985109078\n",
      "Training completed in 91.894 seconds\n",
      "For rank 8, the validation RMSE is 0.86134568973\n",
      "Training completed in 108.552 seconds\n",
      "For rank 12, the validation RMSE is 0.860909679124\n",
      "The best model was trained with rank 4\n",
      "Training completed in 92.444 seconds\n",
      "For testing data, the RMSE is 0.858461435582\n"
     ]
    }
   ],
   "source": [
    "# import MLLib version of ALS \n",
    "from pyspark.mllib.recommendation import ALS as ALS2\n",
    "import math\n",
    "\n",
    "# split data in trainig testing and validation subsets\n",
    "training_ratings_rdd, validation_ratings_rdd, test_ratings_rdd = ratings_rdd.randomSplit([6, 2, 2], seed=0)\n",
    "# remove ratings from validation and testing datasets\n",
    "validation_for_predict_ratings_rdd = validation_ratings_rdd.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_ratings_rdd = test_ratings_rdd.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "for rank in ranks:\n",
    "    # record training time \n",
    "    t0rdd = time()\n",
    "    # fit the model with these parameters\n",
    "    model2 = ALS2.train(training_ratings_rdd, rank, iterations=max_Iter,\n",
    "                      lambda_=reg_Param)\n",
    "    ttrdd = time() - t0rdd\n",
    "    print (\"Training completed in {} seconds\".format(round(ttrdd,3)))\n",
    "\n",
    "    # create rating predictions against the validation dataframe\n",
    "    predictions_val = model2.predictAll(validation_for_predict_ratings_rdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    # join ratings and predictions to compute rmse\n",
    "    rates_and_preds_val = validation_ratings_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions_val)\n",
    "    # evaluate rmse for predicted ratings\n",
    "    error = math.sqrt(rates_and_preds_val.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    print ('For rank %s, the validation RMSE is %s' % (rank, error))\n",
    "    # record the best rank\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print ('The best model was trained with rank %s' % best_rank)\n",
    "# fit the model for best rank\n",
    "t0rdd = time()\n",
    "model2 = ALS2.train(training_ratings_rdd, 4, iterations=max_Iter,lambda_=reg_Param)\n",
    "ttrdd = time() - t0rdd\n",
    "print (\"Training completed in {} seconds\".format(round(ttrdd,3)))\n",
    "\n",
    "# compute rmse for testing dataset \n",
    "predictions_test = model2.predictAll(test_for_predict_ratings_rdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds_test = test_ratings_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions_test)\n",
    "error = math.sqrt(rates_and_preds_test.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "print ('For testing data, the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed in 14.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=11, product=2502, rating=4.246173387283797),\n",
       " Rating(user=11, product=3623, rating=2.532487153760588)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try creating recommendation for a user \n",
    "single_user = test_ratings_rdd.filter(lambda line: line[0]=='11').map(lambda x: (x[0], x[1]))\n",
    "test_ratings_rdd.take(2),test_ratings_rdd.count(),single_user.count()\n",
    "t0rdd = time()\n",
    "reccomendations = model2.predictAll(single_user)\n",
    "ttrdd = time() - t0rdd\n",
    "print (\"Prediction completed in {} seconds\".format(round(ttrdd,3)))\n",
    "reccomendations.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
